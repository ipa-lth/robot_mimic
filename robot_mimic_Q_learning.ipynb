{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!python3 -m pip install --upgrade Pillow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gym_robotmimic.EnvRobot import EnvRobot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import numpy as np\n",
    "import time\n",
    "from IPython import display\n",
    "import random\n",
    "import itertools\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7ff590aa4250>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "pos = (0, 50)\n",
    "env = EnvRobot(pos, \n",
    "               [(20, 10), (40, 5)], # arm length and width\n",
    "               [0, 95*math.pi/180]) # initial angles\n",
    "\n",
    "env.setObservationSpace(70, 100)\n",
    "\n",
    "env.setGoalRobot(pos, \n",
    "                 [(10, 10), (25, 7), (25, 7)], # (arm length and width)\n",
    "                 #[0,0,0]) # initial angles\n",
    "                 [0, -45*math.pi/180, -90*math.pi/180]) # initial angles\n",
    "\n",
    "#env.turn([0, 90*math.pi/180])\n",
    "img = env.plot(goal=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# discretized actions -> functions\n",
    "def action_plus(env):\n",
    "    if env.links[1]['angle'] < 90*math.pi/180:\n",
    "        env.turn([0, 5*math.pi/180])\n",
    "    \n",
    "def action_minus(env):\n",
    "    if env.links[1]['angle'] > -90*math.pi/180:\n",
    "        env.turn([0, -5*math.pi/180])\n",
    "        \n",
    "def action_stay(env):\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7ff590ac7250>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "env.reset()\n",
    "reward = []\n",
    "\n",
    "r = np.arange(-95, 96, 5)\n",
    "for i in r:\n",
    "    action_minus(env)\n",
    "    reward.append(env.getReward())\n",
    "    img = env.plot(goal=True)\n",
    "\n",
    "    time.sleep(0.1)\n",
    "    display.clear_output(wait=True)\n",
    "    display.display(img)\n",
    "display.clear_output(wait=True)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# Save as gif\n",
    "env.reset()\n",
    "im = []\n",
    "reward = []\n",
    "\n",
    "r = np.arange(-95, 96, 5)\n",
    "for i in r:\n",
    "    action_minus(env)\n",
    "    reward.append(env.getReward())\n",
    "    img = env.plot(goal=True)\n",
    "    im.append(img)\n",
    "    \n",
    "im[0].save('out.gif', save_all=True, append_images=im[1:], optimize=False, duration=0.2*len(im), loop=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7ff59082bc10>]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7ff5909c2cd0>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(reward)\n",
    "#plt.savefig('rewards.png')"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "env.reset()\n",
    "env.getRewardScaling(-90, 90, 5)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "env.reset()\n",
    "reward = []\n",
    "\n",
    "r = np.arange(-90, 96, 5)\n",
    "for i in r:\n",
    "    action_minus(env)\n",
    "    reward.append(env.getReward())\n",
    "    img = env.plot(goal=True)\n",
    "    \n",
    "    time.sleep(0.1)\n",
    "    display.clear_output(wait=True)\n",
    "    display.display(img)\n",
    "display.clear_output(wait=True)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "plt.plot(reward)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "############## Initializing #################\n",
    "\n",
    "# Q-Learning (naive)\n",
    "\n",
    "# init Q(s,a)\n",
    "# axis space -90° - +90°; 5° steps -> 36 steps\n",
    "# s Observation space = goal_axis * quantified(goal state) + axis * quantified(axis state) = (2 + 1) * 36 = 108\n",
    "# a action space = axis * direction = 1 * 2 = 2\n",
    "\n",
    "#Q = np.zeros((38, 38, 38, 3)) # | goal axis 1 | goal axis 2 | current axis | actions |\n",
    "Q = np.zeros((38, 38, 3)) # | goal axis 1 | current axis | actions |\n",
    "\n",
    "Q_mean = [np.mean(Q)]\n",
    "Rewards_max = [0]\n",
    "Rewards_mean = [0]\n",
    "\n",
    "\n",
    "alpha = 0.1 # alpha\n",
    "gamma = 0.95 # gamma\n",
    "\n",
    "show_live = False\n",
    "env.reset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_string = \"Q-{}_{}_{}\".format(Q.size, alpha, gamma)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "############### Loading .npz file #############\n",
    "\n",
    "#np.savez(file_string, Q=Q, Rewards_max=Rewards_max, Rewards_mean=Rewards_mean, Q_mean=Q_mean)\n",
    "file_dict = np.load(file_string+'.npz')\n",
    "print(file_dict.files)\n",
    "\n",
    "Q = file_dict['Q']\n",
    "Rewards_mean = file_dict['Rewards_mean']\n",
    "Rewards_max = file_dict['Rewards_max']\n",
    "Q_mean = file_dict['Q_mean']\n",
    "\n",
    "print(np.max(Q))\n",
    "print(np.min(Q))\n",
    "print(np.mean(Q))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epsilon = 0.7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rcParams['figure.figsize'] = [14, 6]\n",
    "show_live = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "env.reset()\n",
    "env.plot(goal=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#%%time # JUPYTER MAGIC to measure runtime\n",
    "############### Vanilla Q-Learning ###############\n",
    "# Swipes the goal axis up and down, step by step #\n",
    "# providing high reward in nearby positions      #\n",
    "#                                                #\n",
    "#  IDEA TO USE PROXIMITY FOR FASTER LEARNING     #\n",
    "##################################################\n",
    "\n",
    "env.reset()\n",
    "\n",
    "# Repeat until convergence\n",
    "for i, rand1 in enumerate(itertools.cycle(range(70, -70, -5) + range(-70, 70, 5))):\n",
    "    if i > 60*60*2: break # about 2h on my machine\n",
    "    rewards = []\n",
    "    robot_goal_state = [0, rand1*math.pi/180]\n",
    "    \n",
    "    env.setGoalRobot(pos, \n",
    "                 #[(10, 10), (25, 7), (25, 7)], # arm length and width\n",
    "                 [(10, 10), (50, 7)], # arm length and width\n",
    "                 robot_goal_state) # initial angles\n",
    "        \n",
    "    #Repeat until termination\n",
    "    for j in range(1, 500):\n",
    "        # Get state entry\n",
    "        i0 = int((robot_goal_state[1] + 90*math.pi/180) / (5*math.pi/180)) # goal robot state 1 \n",
    "        #i1 = int((robot_goal_state[2] + 90*math.pi/180) / (5*math.pi/180)) # goal robot state 2\n",
    "        i2 = int((env.links[1]['angle'] + 90*math.pi/180) / (5*math.pi/180)) # robot state 1 \n",
    "        \n",
    "        #Q_state = Q[i0, i1, i2]\n",
    "        Q_state = Q[i0, i2]\n",
    "        #print(\"{}, {}, {} : {}\".format(i0, i1, i2, Q_state)\n",
    "        \n",
    "        if random.random() > epsilon:\n",
    "            # Exploit\n",
    "            if not all(x == Q_state[0] for x in Q_state):\n",
    "                #print(\"exploit\")\n",
    "                a = np.unravel_index(Q_state.argmax(), Q_state.shape)[0] # get the index of the max; hacky unfold tuple\n",
    "                last_explore_a = None\n",
    "            else:\n",
    "                #print(\"exploit: don't care\")\n",
    "                a = random.choice([0, 1, 2])\n",
    "        else:\n",
    "            # Explore\n",
    "            #print(\"explore\")\n",
    "            a = random.choice([0, 1, 2])\n",
    "\n",
    "        \n",
    "        # Take Action\n",
    "        if a == 0:\n",
    "            #print(\"Action plus\")\n",
    "            action_plus(env)\n",
    "            if i2 < Q.shape[1]:\n",
    "                i2_next = i2 + 1\n",
    "            else:\n",
    "                i2_next = i2\n",
    "        elif a == 1:\n",
    "            #print(\"Action minus\")\n",
    "            action_minus(env)\n",
    "            if i2 > 0:\n",
    "                i2_next = i2 - 1\n",
    "            else:\n",
    "                i2_next = i2\n",
    "        else:\n",
    "            #print(\"Action stay\")\n",
    "            action_stay(env)\n",
    "            i2_next = i2\n",
    "            \n",
    "        if show_live:\n",
    "            img = env.plot(goal=True)\n",
    "            display.clear_output(wait=True)\n",
    "            display.display(img)\n",
    "            #time.sleep(0.1)\n",
    "        \n",
    "        # Update Q\n",
    "        r = env.getReward()\n",
    "        #Q[i0, i1, i2, a] = (1 - alpha) * Q[i0, i1, i2, a] + alpha * (r + gamma * np.argmax(Q[i0, i1, i2_next]))\n",
    "        Q[i0, i2, a] = (1 - alpha) * Q[i0, i2, a] + alpha * (r + gamma * np.argmax(Q[i0, i2_next]))\n",
    "        \n",
    "        rewards.append(r)\n",
    "    \n",
    "    Q_mean = np.append(Q_mean, np.mean(Q))\n",
    "    Rewards_mean = np.append(Rewards_mean, np.mean(rewards))\n",
    "    Rewards_max = np.append(Rewards_max, np.max(rewards))\n",
    "    \n",
    "    # save every episode\n",
    "    np.savez(file_string, Q=Q, Rewards_max=Rewards_max, Rewards_mean=Rewards_mean, Q_mean=Q_mean)\n",
    "    \n",
    "    if not show_live:\n",
    "        display.clear_output(wait=True)\n",
    "        print(\"Loop: {} with {} steps\".format(i, j))\n",
    "        print(\"Goal state: {}\".format(rand1))\n",
    "        print(\"Max Rewards : {}\".format(Rewards_max[-1]))\n",
    "        print(\"Mean Rewards: {}\".format(Rewards_mean[-1]))\n",
    "        print(\"Mean Q: {}\".format(Q_mean[-1]))\n",
    "\n",
    "        plt.plot(Rewards_max)\n",
    "        plt.plot(Rewards_mean)\n",
    "        plt.plot(Q_mean)\n",
    "        plt.legend([\"max reward\", \"mean reward\", \"mean Q\"])\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#%%time # JUPYTER MAGIC to measure runtime\n",
    "############### Vanilla Q-Learning ###############\n",
    "# Random goal axis                               #\n",
    "# Random starting position                       #\n",
    "#                                                #\n",
    "##################################################\n",
    "\n",
    "\n",
    "# Repeat until ...\n",
    "for i in range(1, 60*60*2):\n",
    "    #env.reset()\n",
    "    rewards = []\n",
    "    rand1 = random.randrange(-70, 75, 5)\n",
    "    #rand2 = random.randrange(-90, 95, 5)\n",
    "    #robot_goal_state = [0, rand1*math.pi/180, rand2*math.pi/180]\n",
    "    robot_goal_state = [0, rand1*math.pi/180]\n",
    "    \n",
    "    env.setGoalRobot(pos, \n",
    "                 #[(10, 10), (25, 7), (25, 7)], # arm length and width\n",
    "                 [(10, 10), (50, 7)], # arm length and width\n",
    "                 robot_goal_state) # initial angles\n",
    "        \n",
    "    for j in range(1, 500):\n",
    "        # Get state entry\n",
    "        i0 = int((robot_goal_state[1] + 90*math.pi/180) / (5*math.pi/180)) # goal robot state 1 \n",
    "        #i1 = int((robot_goal_state[2] + 90*math.pi/180) / (5*math.pi/180)) # goal robot state 2\n",
    "        i2 = int((env.links[1]['angle'] + 90*math.pi/180) / (5*math.pi/180)) # robot state 1 \n",
    "        \n",
    "        #Q_state = Q[i0, i1, i2]\n",
    "        Q_state = Q[i0, i2]\n",
    "        \n",
    "        if random.random() > epsilon:\n",
    "            # Exploit\n",
    "            if not all(x == Q_state[0] for x in Q_state):\n",
    "                #print(\"exploit\")\n",
    "                a = np.unravel_index(Q_state.argmax(), Q_state.shape)[0] # get the index of the max; hacky unfold tuple\n",
    "            else:\n",
    "                #print()\"exploit: don't care\")\n",
    "                a = random.choice([0,1,2])\n",
    "        else:\n",
    "            # Explore\n",
    "            #print(\"explore\")\n",
    "            a = random.choice([0,1,2])\n",
    "\n",
    "        # Take Action\n",
    "        if a == 0:\n",
    "            #print(\"Action plus\")\n",
    "            action_plus(env)\n",
    "            if i2 < Q.shape[1]:\n",
    "                i2_next = i2 + 1\n",
    "            else:\n",
    "                i2_next = i2\n",
    "        elif a == 1:\n",
    "            #print(\"Action minus\")\n",
    "            action_minus(env)\n",
    "            if i2 > 0:\n",
    "                i2_next = i2 - 1\n",
    "            else:\n",
    "                i2_next = i2\n",
    "        else:\n",
    "            #print(\"Action stay\")\n",
    "            action_stay(env)\n",
    "            i2_next = i2\n",
    "            \n",
    "        if show_live:\n",
    "            img = env.plot(goal=True)\n",
    "            display.clear_output(wait=True)\n",
    "            display.display(img)\n",
    "            #time.sleep(0.1)\n",
    "        \n",
    "        # Update Q\n",
    "        r = env.getReward()\n",
    "        #Q[i0, i1, i2, a] = (1 - alpha) * Q[i0, i1, i2, a] + alpha * (r + gamma * np.argmax(Q[i0, i1, i2_next]))\n",
    "        Q[i0, i2, a] = (1 - alpha) * Q[i0, i2, a] + alpha * (r + gamma * np.argmax(Q[i0, i2_next]))\n",
    "\n",
    "        rewards.append(r)\n",
    "\n",
    "    Q_mean = np.append(Q_mean, np.mean(Q))\n",
    "    Rewards_mean = np.append(Rewards_mean, np.mean(rewards))\n",
    "    Rewards_max = np.append(Rewards_max, np.max(rewards))\n",
    "    \n",
    "    #save every episode\n",
    "    np.savez(file_string, Q=Q, Rewards_max=Rewards_max, Rewards_mean=Rewards_mean, Q_mean=Q_mean)\n",
    "    \n",
    "    if not show_live:\n",
    "        display.clear_output(wait=True)\n",
    "        print(\"Loop: {} with {} steps\".format(i, j))\n",
    "        print(\"Goal state: {}\".format(rand1))\n",
    "        print(\"Max Rewards : {}\".format(Rewards_max[-1]))\n",
    "        print(\"Mean Rewards: {}\".format(Rewards_mean[-1]))\n",
    "        print(\"Mean Q: {}\".format(Q_mean[-1]))\n",
    "\n",
    "        #print(\"Std Rewards\", np.std(rewards))\n",
    "        plt.plot(Rewards_max)\n",
    "        plt.plot(Rewards_mean)\n",
    "        plt.plot(Q_mean)\n",
    "        plt.legend([\"max reward\", \"mean reward\", \"mean Q\"])\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.savez(\"bck_\"+file_string, Q=Q, Rewards_max=Rewards_max, Rewards_mean=Rewards_mean, Q_mean=Q_mean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
